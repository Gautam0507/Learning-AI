{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "LPsx8O9au7"
      },
      "source": [
        "## Creating the environement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "EfHSyufvSz"
      },
      "source": [
        "import statistics\n",
        "\n",
        "import gymnasium as gym\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import pygame\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from env import SimpleCorridor"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "BnKbgj0puj"
      },
      "source": [
        "## Test Agent Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "0v7QHErL6L"
      },
      "source": [
        "def test_agent(env: gym.Env, policy: callable, episodes: int = 10) -> None:\n",
        "    for episode in range(episodes):\n",
        "        temp = env.reset()\n",
        "        tagent_pos = temp[0]\n",
        "        ttarget_pos = temp[1]\n",
        "        done = False\n",
        "\n",
        "        env.render(mode=\"rgb_array\")\n",
        "        while not done:\n",
        "            action = policy(tagent_pos, 0.1)\n",
        "\n",
        "            next_state, _, done, _ = env.step(action)\n",
        "            env.render()\n",
        "            plt.axis(\"off\")\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "\n",
        "            tagent_pos = next_state[0]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "5nwzYEIp0J"
      },
      "source": [
        "## Initialising the environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "TgPzPWonJf"
      },
      "source": [
        "env = SimpleCorridor()\n",
        "env.reset()\n",
        "env.render()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "CU4dsJfEzX"
      },
      "source": [
        "## Q Value Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "YVFwY9uHzA"
      },
      "source": [
        "action_values = np.zeros(shape=(15, 2))\n",
        "print(action_values)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "j7qgEeYhlK"
      },
      "source": [
        "### Creating the Policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "YWHrtX0c0K"
      },
      "source": [
        "def policy(state, epsilon=0.1):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.choice(2)\n",
        "    else:\n",
        "        av = action_values[state]\n",
        "        return np.random.choice(np.flatnonzero(av == av.max()))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ykdfruagrZ"
      },
      "source": [
        "action = policy(0, epsilon=0.5)\n",
        "print(f\"The action taken in state 0 is {action}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "hKJN62Wsnn"
      },
      "source": [
        "#### Testing the policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "aUGXvzUKEL"
      },
      "source": [
        "# Implementing the algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "QK5RxLYJ6O"
      },
      "source": [
        "def on_policy_mc_control(policy, action_values, episodes=1000, epsilon=0.1, gamma=0.99):\n",
        "    sa_returns = np.empty((15, 2), dtype=object)\n",
        "\n",
        "    for episode in range(0, episodes + 1):\n",
        "        state, target = env.reset()\n",
        "        done = False\n",
        "        transitions = []\n",
        "\n",
        "        while not done:\n",
        "            action = policy(state, epsilon)\n",
        "            (next_state, target), reward, done, info = env.step(action)\n",
        "            transitions.append([state, action, reward])\n",
        "            state = next_state\n",
        "\n",
        "        G = 0\n",
        "\n",
        "        for state_t, action_t, reward_t in reversed(transitions):\n",
        "            G = reward_t + gamma * G\n",
        "            if sa_returns[state_t, action_t] == None:\n",
        "                sa_returns[state_t, action_t] = [G]\n",
        "            else:\n",
        "                sa_returns[state_t, action_t].append(G)\n",
        "            action_values[state_t, action_t] = statistics.mean(\n",
        "                sa_returns[state_t, action_t]\n",
        "            )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "kpQ7BW0OvR"
      },
      "source": [
        "on_policy_mc_control(policy, action_values)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "f6Ex2vJpJv"
      },
      "source": [
        "test_agent(env, policy, episodes=10)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}