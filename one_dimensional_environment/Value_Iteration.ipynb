{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCorridor(gym.Env):\n",
    "    def __init__(self, size=15):\n",
    "        self.length = size\n",
    "        self.start_pos = 12\n",
    "        self.end_pos = 5\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            0.0, self.length, shape=(2,), dtype=int)\n",
    "        self.mode = \"rgb_array\"\n",
    "        self.width = 20\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_pos = self.start_pos\n",
    "        return np.array([self.current_pos, self.end_pos])\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0 and self.current_pos > 0:\n",
    "            self.current_pos -= 1\n",
    "        if action == 1 and self.current_pos < self.length - 1:\n",
    "            self.current_pos += 1\n",
    "        done = self.current_pos == self.end_pos\n",
    "        reward = 1 if done else -1\n",
    "        info = {}\n",
    "        return np.array([self.current_pos, self.end_pos]), reward, done, info\n",
    "\n",
    "    def simulate_step(self, tpos, action):\n",
    "        if action == 0 and tpos > 0:\n",
    "            tpos -= 1\n",
    "        if action == 1 and tpos < self.length -1:\n",
    "            tpos += 1\n",
    "            \n",
    "        done = tpos == self.end_pos\n",
    "        reward = 1 if done else -1\n",
    "        info = {}\n",
    "        return tpos, reward, done, info\n",
    "        \n",
    "    def render(self, mode=\"rgb_array\"):\n",
    "        canvas = pygame.Surface((self.width, self.width * self.length + 1))\n",
    "        canvas.fill((255,255,255))\n",
    "        for i in range(self.length+1):\n",
    "            pygame.draw.line(canvas, 0, (0, 20*(i)), (20, 20*(i)), width=1)\n",
    "        pygame.draw.line(canvas, 0, (0,0), (0, 20*(i)), width=1)\n",
    "        pygame.draw.line(canvas, 0, (19,0), (19, 20*(i)), width=1)\n",
    "        pygame.draw.circle(canvas, (0, 0, 255), (10,self.current_pos*20+10), 7)\n",
    "        pygame.draw.circle(canvas, (255, 0, 0), (10,(self.end_pos)*20+10), 7)\n",
    "        plArray = np.array(pygame.surfarray.pixels3d(canvas))\n",
    "        plt.imshow(plArray)        \n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleCorridor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "policy_probs = np.full((15,2),0.5)\n",
    "print(policy_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(cur_pos):\n",
    "    return policy_probs[cur_pos]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the policy with state (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity of taking action 0: 0.5\n",
      "Probablity of taking action 1: 0.5\n"
     ]
    }
   ],
   "source": [
    "action_probablities = policy(0)\n",
    "for action, prob in zip(range(2), action_probablities):\n",
    "    print(f\"Probablity of taking action {action}: {prob}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The test agent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(env: gym.Env, policy: callable, episodes: int = 10) -> None: \n",
    "    for episode in range(episodes):\n",
    "        temp = env.reset()\n",
    "        tagent_pos = temp[0]\n",
    "        ttarget_pos = temp[1]\n",
    "        done = False  \n",
    "       \n",
    "        env.render(mode=\"rgb_array\")\n",
    "        while not done:\n",
    "            p = policy(tagent_pos)\n",
    "            action = np.random.choice(2,p=p)\n",
    "\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            env.render()\n",
    "            plt.axis('off')\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            \n",
    "            \n",
    "            tagent_pos = next_state[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the value table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = np.zeros(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(state_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the agent with the random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_agent(env, policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Value iteration Algoritm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(policy_probs, state_values, theta = 1e-6, gamma = 0.99):\n",
    "    delta = float(\"inf\")\n",
    "\n",
    "    while delta > theta: \n",
    "        delta = 0\n",
    "\n",
    "        for pos in range(15):\n",
    "            old_value = state_values[pos]\n",
    "            action_probs = None\n",
    "            max_qsa = float(\"-inf\")\n",
    "\n",
    "            for action in range(2):\n",
    "                next_state, reward, _,_ = env.simulate_step(pos, action)\n",
    "                qsa = reward + gamma * state_values[next_state]\n",
    "            \n",
    "                if qsa > max_qsa:\n",
    "                    max_qsa = qsa\n",
    "                    action_probs = np.zeros(2)\n",
    "                    action_probs[action] = 1\n",
    "\n",
    "            state_values[pos] = max_qsa\n",
    "            policy_probs[pos] = action_probs\n",
    "            delta = max(delta, abs(max_qsa - old_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_iteration(policy_probs, state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.45763847 -2.48246409 -1.49743945 -0.50246505  0.5025596  -0.502466\n",
      "  0.50255866 -0.50246692 -1.49744225 -2.48246783 -3.45764315 -4.42306672\n",
      " -5.37883605 -6.32504769 -7.26179722]\n"
     ]
    }
   ],
   "source": [
    "print(state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(policy_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_agent(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
