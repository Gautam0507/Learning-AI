{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration for the 2d Grid env"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Grid_World\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env_Size = 4\n",
    "env = Grid_World(size= Env_Size, type= \"fixed\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e83610b160>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state, target = env.reset()\n",
    "frame = env.render()\n",
    "plt.axis('off')\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]\n",
      "\n",
      " [[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]\n",
      "\n",
      " [[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]\n",
      "\n",
      " [[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]]]\n"
     ]
    }
   ],
   "source": [
    "policy_probablities = np.full((Env_Size, Env_Size, 4), 0.25)\n",
    "print(policy_probablities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state):\n",
    "    policy_probs = policy_probablities[state]\n",
    "    return np.random.choice(4,p = policy_probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the policy with state 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "action = policy((0,0))\n",
    "print(action)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the value table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = np.zeros((Env_Size, Env_Size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(policy_probablities, state_values, theta = 1e-6, gamma = 0.99):\n",
    "    delta = float(\"inf\")\n",
    "\n",
    "    while delta > theta: \n",
    "        delta = 0\n",
    "        for row in range(Env_Size):\n",
    "            for col in range(Env_Size):\n",
    "                old_value = state_values[row,col]\n",
    "                action_probs = None\n",
    "                max_qsa = float(\"-inf\")\n",
    "\n",
    "                for action in range(4):\n",
    "                    (next_row, next_col), reward, _, _ = env.simulate_step((row,col), action)\n",
    "                    qsa = reward + gamma * state_values[(next_row, next_col)]\n",
    "\n",
    "                    if qsa > max_qsa:\n",
    "                        max_qsa = qsa\n",
    "                        action_probs = np.zeros(4)\n",
    "                        action_probs[action] = 1\n",
    "\n",
    "                state_values[(row,col)] = max_qsa\n",
    "                policy_probablities[(row,col)] = action_probs\n",
    "                delta = max(delta, abs(max_qsa - old_value))\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_iteration(policy_probablities, state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(state_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(policy_probablities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(policy, episodes = 1, epsilon = 0):\n",
    "    env.render_mode = Render_mode\n",
    "    if env.render_mode == \"human\":\n",
    "        env.py_init()\n",
    "    \n",
    "    for episode in range(0,episodes):\n",
    "        state, _= env.reset()\n",
    "        done = False\n",
    "        while not done: \n",
    "            action = policy(state,epsilon)\n",
    "            state, _, done, _ = env.step(action)\n",
    "            frame = env.render()\n",
    "            if env.render_mode == \"rgb_array\":\n",
    "                plt.imshow(frame)\n",
    "                plt.axis = ('off')\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait = True)\n",
    "    if env.render_mode == \"human\":\n",
    "        env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Render_mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_agent(env, policy)\n",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m, in \u001b[0;36mtest_agent\u001b[1;34m(policy, episodes, epsilon)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_agent\u001b[39m(policy, episodes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, epsilon \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     env\u001b[39m.\u001b[39mrender_mode \u001b[39m=\u001b[39m Render_mode\n\u001b[0;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m env\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m      4\u001b[0m         env\u001b[39m.\u001b[39mpy_init()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Render_mode' is not defined"
     ]
    }
   ],
   "source": [
    "test_agent(env, policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
